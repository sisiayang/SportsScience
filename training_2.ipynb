{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from keras.layers import Embedding, Masking, Concatenate, GRU, Dense, Reshape\n",
    "from model import CNN_with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rally: 1292\n",
    "# Score: 891\n",
    "# Errors: 1288\n",
    "# 至少其中一個一定有 -> 先用 Error 來看，沒有再用 Score 來看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rally_result(df):\n",
    "    result_label = []\n",
    "    ignor_game_rally_index = []\n",
    "    team_col = [c for c in df.columns if 'Team' in c]\n",
    "    for _, df_rally in df.groupby(['Game', 'Rally']):\n",
    "        start_from = df.iloc[df_rally.index[0]][team_col].tolist()\n",
    "\n",
    "        result = df_rally[df_rally['Score'] == 1]\n",
    "        if(len(result) != 0):\n",
    "            if(result.iloc[0][team_col].tolist() == start_from):\n",
    "                result_label.append([0, 1])\n",
    "            else:\n",
    "                result_label.append([1, 0])\n",
    "        else:\n",
    "            result = df_rally[df_rally['Errors'] == 1]\n",
    "            if(len(result) == 0):\n",
    "                ignor_game_rally_index.append((df_rally.iloc[0]['Game'], df_rally.iloc[0]['Rally']))\n",
    "            elif(result.iloc[0][team_col].tolist() != start_from):\n",
    "                result_label.append([0, 1])\n",
    "            else:\n",
    "                result_label.append([1, 0])\n",
    "    return tf.constant(result_label, dtype=float), ignor_game_rally_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, ignor = get_rally_result(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding_data(df, ignor):\n",
    "    space_col = [c for c in df.columns if 'Space' in c]\n",
    "    action_col = [c for c in df.columns if 'Action' in c]\n",
    "    result_col = ['Errors', 'Score', 'Nothing']\n",
    "    others_col = [c for c in df.columns if c not in space_col and c not in action_col and c not in result_col and c != 'Game' and c != 'Rally']\n",
    "    team_col = [c for c in df.columns if 'Team' in c]\n",
    "\n",
    "    rally_set = []\n",
    "    rally_space_set = []\n",
    "    rally_action_set = []\n",
    "    for _, df_rally in df.groupby(['Game', 'Rally']):   # each rally in one game\n",
    "        if((df_rally.iloc[0]['Game'], df_rally.iloc[0]['Rally']) in ignor):\n",
    "            continue\n",
    "        start_from = df.iloc[df_rally.index[0]][team_col].tolist()\n",
    "        shot_set = []\n",
    "        shot_space_set = []\n",
    "        shot_action_set = []\n",
    "        \n",
    "        atk_sequence = []\n",
    "        atk_space_sequence = []\n",
    "        atk_action_sequence = []\n",
    "\n",
    "        curr_team = start_from\n",
    "        for _, shot in df_rally.iterrows():\n",
    "            if(shot[team_col].tolist() != curr_team):\n",
    "                shot_set.append(atk_sequence)\n",
    "                shot_space_set.append(atk_space_sequence)\n",
    "                shot_action_set.append(atk_action_sequence)\n",
    "                \n",
    "                curr_team = shot[team_col].tolist()\n",
    "\n",
    "                atk_sequence = []\n",
    "                atk_space_sequence = []\n",
    "                atk_action_sequence = []\n",
    "\n",
    "            atk_space_sequence.append(shot[space_col])\n",
    "            atk_action_sequence.append(shot[action_col])\n",
    "            atk_sequence.append(shot[others_col])\n",
    "        \n",
    "        # the last shot\n",
    "        shot_set.append(atk_sequence)\n",
    "        shot_space_set.append(atk_space_sequence)\n",
    "        shot_action_set.append(atk_action_sequence)\n",
    "\n",
    "        # one rally has been finished\n",
    "        shot_set = pad_sequences(shot_set, maxlen=3, padding='post')\n",
    "        shot_space_set = pad_sequences(shot_space_set, maxlen=3, padding='post')\n",
    "        shot_action_set = pad_sequences(shot_action_set, maxlen=3, padding='post')\n",
    "\n",
    "        # one rally has been finished\n",
    "        rally_set.append(shot_set)\n",
    "        rally_space_set.append(shot_space_set)\n",
    "        rally_action_set.append(shot_action_set)\n",
    "\n",
    "    padded_rally_set = pad_sequences(rally_set, dtype=float, padding='post')\n",
    "    padded_rally_space_set = pad_sequences(rally_space_set, dtype=float, padding='post')\n",
    "    padded_rally_action_set = pad_sequences(rally_action_set, dtype=float, padding='post')\n",
    "    \n",
    "    return padded_rally_set, padded_rally_space_set, padded_rally_action_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_replace = {list(df.groupby('Space').groups.keys())[i]: i+1 for i in range(len(df.groupby('Space')))}\n",
    "action_replace = {list(df.groupby('Action').groups.keys())[i]: i+1 for i in range(len(df.groupby('Action')))}\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Team', 'No.'])\n",
    "df = df.replace(space_replace)\n",
    "df = df.replace(action_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1291, 14, 3, 36)\n",
      "(1291, 14, 3, 1)\n",
      "(1291, 14, 3, 1)\n",
      "(1291, 2)\n"
     ]
    }
   ],
   "source": [
    "rally_set, rally_space_set, rally_action_set= get_padding_data(df, ignor)\n",
    "\n",
    "# rally數, 最大回合數in one rally, 3, feature數\n",
    "print(rally_set.shape)\n",
    "print(rally_space_set.shape)\n",
    "print(rally_action_set.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_space_set = rally_space_set.squeeze()\n",
    "rally_action_set = rally_action_set.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_set_tensor = tf.convert_to_tensor(rally_set)\n",
    "rally_space_set_tensor = tf.convert_to_tensor(rally_space_set)\n",
    "rally_action_set_tensor = tf.convert_to_tensor(rally_action_set)\n",
    "rally_result_tensor = tf.convert_to_tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rally_num = rally_set.shape[0]\n",
    "rally_size = rally_set.shape[1]\n",
    "shot_size = 3\n",
    "feature_dim = (rally_set.shape[-1], len(df.groupby('Space'))+1, len(df.groupby('Action'))+1)\n",
    "space_embed_size = 8\n",
    "action_embed_size = 8\n",
    "shot_embed_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size):\n",
    "    '''\n",
    "    framework: \n",
    "    1. 對 space, action 做 embeding, (input, output) = (feature_dim, embed_size)\n",
    "    2. concat space, action, others 成一個 embedded vector for each atk, (input) =  ([feature_dim, embed_size, embed_size])\n",
    "    3. 先做 embedding\n",
    "    4. CNN, filters = shot_embed_size\n",
    "    5. GRU\n",
    "    '''\n",
    "    # each input: 三個維度, rally shot feature\n",
    "    input_others = keras.Input(shape=(rally_size, shot_size, feature_dim[0]))\n",
    "    input_space = keras.Input(shape=(rally_size, shot_size))\n",
    "    input_action = keras.Input(shape=(rally_size, shot_size))\n",
    "\n",
    "    # space & action 先做 embedding, 再和 others concat\n",
    "    embed_space_layer = Embedding(input_dim=feature_dim[1], output_dim=space_embed_size, mask_zero=True, name='Space_Embedding')\n",
    "    embed_action_layer = Embedding(input_dim=feature_dim[2], output_dim=action_embed_size, mask_zero=True, name='Action_Embedding')\n",
    "    masking_layer = Masking(mask_value=0)   # for input_others (還沒有經過mask)\n",
    "    concat_layer = Concatenate(name='Input_Concat')\n",
    "\n",
    "    embed_shot_layer = CNN_with_mask(kernel_size=3, filters=shot_embed_size, strides=3, name='Shot_Embedding')\n",
    "\n",
    "    cnn_layer = CNN_with_mask(kernel_size=3, filters=shot_embed_size, strides=1, name='CNN_Layer')\n",
    "    gru_layer = GRU(units=16, name='GRU_Layer')\n",
    "    dense_layer = Dense(units=2, activation='softmax')\n",
    "\n",
    "    # forward\n",
    "    inputs = [input_others, input_space, input_action]\n",
    "\n",
    "    embed_space = embed_space_layer(input_space)\n",
    "    embed_action = embed_action_layer(input_action)\n",
    "    masked_others = masking_layer(tf.cast(input_others, tf.float32))\n",
    "    embed_input = concat_layer([masked_others, embed_space, embed_action])\n",
    "    embed_shot = tf.squeeze(embed_shot_layer(embed_input), axis=2)\n",
    "\n",
    "    cnn_output = cnn_layer(embed_shot)\n",
    "    gru_output = gru_layer(cnn_output)\n",
    "    output = dense_layer(gru_output)\n",
    "    model = keras.Model(inputs=inputs, outputs=output, name='Classification')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Classification\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 14, 3, 36)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_6 (TFOpLambda)          (None, 14, 3, 36)    0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 14, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           [(None, 14, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_6 (Masking)             (None, 14, 3, 36)    0           tf.cast_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Space_Embedding (Embedding)     (None, 14, 3, 8)     152         input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Action_Embedding (Embedding)    (None, 14, 3, 8)     128         input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Input_Concat (Concatenate)      (None, 14, 3, 52)    0           masking_6[0][0]                  \n",
      "                                                                 Space_Embedding[0][0]            \n",
      "                                                                 Action_Embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "cnn_with_mask_12 (CNN_with_mask (None, 14, 1, 16)    2512        Input_Concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_6 (TFOpLam (None, 14, 16)       0           cnn_with_mask_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "cnn_with_mask_13 (CNN_with_mask (None, 14, 16)       784         tf.compat.v1.squeeze_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "GRU_Layer (GRU)                 (None, 16)           1632        cnn_with_mask_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            34          GRU_Layer[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,242\n",
      "Trainable params: 5,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(others_tensor, space_tensor, action_tensor, label_tensor):\n",
    "    l = label_tensor.shape[0]\n",
    "    split_persentage = int(l*0.7)\n",
    "\n",
    "    train_space = space_tensor[:split_persentage]\n",
    "    train_action = action_tensor[:split_persentage]\n",
    "    train_others = others_tensor[:split_persentage]\n",
    "    train_label = label[:split_persentage]\n",
    "\n",
    "    test_space = space_tensor[split_persentage:]\n",
    "    test_action = action_tensor[split_persentage:]\n",
    "    test_others = others_tensor[split_persentage:]\n",
    "    test_label = label[split_persentage:]\n",
    "\n",
    "    train_x = [train_others, train_space, train_action]\n",
    "    train_y = train_label\n",
    "\n",
    "    test_x = [test_others, test_space, test_action]\n",
    "    test_y = test_label\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = split_data(rally_set_tensor, rally_space_set_tensor, rally_action_set_tensor, rally_result_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularizer = tf.keras.regularizers.l2(0.01)\n",
    "optimizer = 'adam'\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "epochs = 30\n",
    "# callbacks = tf.keras.callbacks.EarlyStopping(min_delta=0.002, patience=15, restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "29/29 [==============================] - 3s 6ms/step - loss: 0.6463 - accuracy: 0.6656\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6382 - accuracy: 0.6656\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6354 - accuracy: 0.6656\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.6247 - accuracy: 0.6711\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.6084 - accuracy: 0.6766\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.6016 - accuracy: 0.6988\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5916 - accuracy: 0.6932\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.5892 - accuracy: 0.6988\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5809 - accuracy: 0.6910\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5617 - accuracy: 0.6977\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.5468 - accuracy: 0.6888\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5303 - accuracy: 0.6921\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.5345 - accuracy: 0.6800\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5226 - accuracy: 0.6766\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.5087 - accuracy: 0.7143\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.4993 - accuracy: 0.7043\n",
      "Epoch 17/30\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.5012 - accuracy: 0.71 - 0s 7ms/step - loss: 0.4920 - accuracy: 0.7220\n",
      "Epoch 18/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4736 - accuracy: 0.7475\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.4583 - accuracy: 0.7708\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.8040\n",
      "Epoch 21/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4100 - accuracy: 0.7996\n",
      "Epoch 22/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.8450\n",
      "Epoch 23/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.3304 - accuracy: 0.8527\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.3003 - accuracy: 0.8793\n",
      "Epoch 25/30\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.2690 - accuracy: 0.8926\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.2418 - accuracy: 0.9003\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.2265 - accuracy: 0.9081\n",
      "Epoch 28/30\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1942 - accuracy: 0.9347\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.2145 - accuracy: 0.9214\n",
      "Epoch 30/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.1854 - accuracy: 0.9336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25e218e66a0>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 3ms/step - loss: 0.6054 - accuracy: 0.8041\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_y_pred = np.argmax(y_pred, axis=1)\n",
    "argmax_test_y = np.argmax(test_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'show_eval_result_2class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-257-3eb823a815c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcalculate_BS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_eval_result_2class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0macc_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margmax_test_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margmax_y_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf1_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margmax_test_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margmax_y_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'show_eval_result_2class'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from evaluate import calculate_BS, f1, show_eval_result_2class\n",
    "\n",
    "acc_score = accuracy_score(argmax_test_y, argmax_y_pred)\n",
    "f1_score = f1(argmax_test_y, argmax_y_pred)\n",
    "auc_score = roc_auc_score(test_y, y_pred)\n",
    "BS = calculate_BS(test_y, y_pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:    0.80\n",
      "f1:          0.69\n",
      "auc:         0.86\n",
      "BS:          0.16\n"
     ]
    }
   ],
   "source": [
    "show_eval_result_2class(acc_score, f1_score, auc_score, BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SportScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

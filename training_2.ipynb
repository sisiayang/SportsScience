{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from keras.layers import Embedding, Masking, Concatenate, GRU, Dense, Reshape\n",
    "from model import CNN_with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rally: 1292\n",
    "# Score: 891\n",
    "# Errors: 1288\n",
    "# 至少其中一個一定有 -> 先用 Error 來看，沒有再用 Score 來看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rally_result(df):\n",
    "    result_label = []\n",
    "    ignor_game_rally_index = []\n",
    "    team_col = [c for c in df.columns if 'Team' in c]\n",
    "    for _, df_rally in df.groupby(['Game', 'Rally']):\n",
    "        start_from = df.iloc[df_rally.index[0]][team_col].tolist()\n",
    "\n",
    "        result = df_rally[df_rally['Score'] == 1]\n",
    "        if(len(result) != 0):\n",
    "            if(result.iloc[0][team_col].tolist() == start_from):\n",
    "                result_label.append([0, 1])\n",
    "            else:\n",
    "                result_label.append([1, 0])\n",
    "        else:\n",
    "            result = df_rally[df_rally['Errors'] == 1]\n",
    "            if(len(result) == 0):\n",
    "                ignor_game_rally_index.append((df_rally.iloc[0]['Game'], df_rally.iloc[0]['Rally']))\n",
    "            elif(result.iloc[0][team_col].tolist() != start_from):\n",
    "                result_label.append([0, 1])\n",
    "            else:\n",
    "                result_label.append([1, 0])\n",
    "    return tf.constant(result_label, dtype=float), ignor_game_rally_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, ignor = get_rally_result(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding_data(df, ignor):\n",
    "    space_col = [c for c in df.columns if 'Space' in c]\n",
    "    action_col = [c for c in df.columns if 'Action' in c]\n",
    "    result_col = ['Errors', 'Score', 'Nothing']\n",
    "    others_col = [c for c in df.columns if c not in space_col and c not in action_col and c not in result_col and c != 'Game' and c != 'Rally']\n",
    "    team_col = [c for c in df.columns if 'Team' in c]\n",
    "\n",
    "    rally_set = []\n",
    "    rally_space_set = []\n",
    "    rally_action_set = []\n",
    "    for _, df_rally in df.groupby(['Game', 'Rally']):   # each rally in one game\n",
    "        if((df_rally.iloc[0]['Game'], df_rally.iloc[0]['Rally']) in ignor):\n",
    "            continue\n",
    "        start_from = df.iloc[df_rally.index[0]][team_col].tolist()\n",
    "        shot_set = []\n",
    "        shot_space_set = []\n",
    "        shot_action_set = []\n",
    "        \n",
    "        atk_sequence = []\n",
    "        atk_space_sequence = []\n",
    "        atk_action_sequence = []\n",
    "\n",
    "        curr_team = start_from\n",
    "        for _, shot in df_rally.iterrows():\n",
    "            if(shot[team_col].tolist() != curr_team):\n",
    "                shot_set.append(atk_sequence)\n",
    "                shot_space_set.append(atk_space_sequence)\n",
    "                shot_action_set.append(atk_action_sequence)\n",
    "                \n",
    "                curr_team = shot[team_col].tolist()\n",
    "\n",
    "                atk_sequence = []\n",
    "                atk_space_sequence = []\n",
    "                atk_action_sequence = []\n",
    "\n",
    "            atk_space_sequence.append(shot[space_col])\n",
    "            atk_action_sequence.append(shot[action_col])\n",
    "            atk_sequence.append(shot[others_col])\n",
    "        \n",
    "        # the last shot\n",
    "        shot_set.append(atk_sequence)\n",
    "        shot_space_set.append(atk_space_sequence)\n",
    "        shot_action_set.append(atk_action_sequence)\n",
    "\n",
    "        # one rally has been finished\n",
    "        shot_set = pad_sequences(shot_set, maxlen=3, padding='post')\n",
    "        shot_space_set = pad_sequences(shot_space_set, maxlen=3, padding='post')\n",
    "        shot_action_set = pad_sequences(shot_action_set, maxlen=3, padding='post')\n",
    "\n",
    "        # one rally has been finished\n",
    "        rally_set.append(shot_set)\n",
    "        rally_space_set.append(shot_space_set)\n",
    "        rally_action_set.append(shot_action_set)\n",
    "\n",
    "    padded_rally_set = pad_sequences(rally_set, dtype=float, padding='post')\n",
    "    padded_rally_space_set = pad_sequences(rally_space_set, dtype=float, padding='post')\n",
    "    padded_rally_action_set = pad_sequences(rally_action_set, dtype=float, padding='post')\n",
    "    \n",
    "    return padded_rally_set, padded_rally_space_set, padded_rally_action_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_replace = {list(df.groupby('Space').groups.keys())[i]: i+1 for i in range(len(df.groupby('Space')))}\n",
    "action_replace = {list(df.groupby('Action').groups.keys())[i]: i+1 for i in range(len(df.groupby('Action')))}\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Team', 'No.'])\n",
    "df = df.replace(space_replace)\n",
    "df = df.replace(action_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1291, 14, 3, 36)\n",
      "(1291, 14, 3, 1)\n",
      "(1291, 14, 3, 1)\n",
      "(1291, 2)\n"
     ]
    }
   ],
   "source": [
    "rally_set, rally_space_set, rally_action_set= get_padding_data(df, ignor)\n",
    "\n",
    "# rally數, 最大回合數in one rally, 3, feature數\n",
    "print(rally_set.shape)\n",
    "print(rally_space_set.shape)\n",
    "print(rally_action_set.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_space_set = rally_space_set.squeeze()\n",
    "rally_action_set = rally_action_set.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_set_tensor = tf.convert_to_tensor(rally_set)\n",
    "rally_space_set_tensor = tf.convert_to_tensor(rally_space_set)\n",
    "rally_action_set_tensor = tf.convert_to_tensor(rally_action_set)\n",
    "rally_result_tensor = tf.convert_to_tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rally_num = rally_set.shape[0]\n",
    "rally_size = rally_set.shape[1]\n",
    "shot_size = 3\n",
    "feature_dim = (rally_set.shape[-1], len(df.groupby('Space'))+1, len(df.groupby('Action'))+1)\n",
    "space_embed_size = 8\n",
    "action_embed_size = 8\n",
    "shot_embed_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size):\n",
    "    '''\n",
    "    framework: \n",
    "    1. 對 space, action 做 embeding, (input, output) = (feature_dim, embed_size)\n",
    "    2. concat space, action, others 成一個 embedded vector for each atk, (input) =  ([feature_dim, embed_size, embed_size])\n",
    "    3. 先做 embedding\n",
    "    4. CNN, filters = shot_embed_size\n",
    "    5. GRU\n",
    "    '''\n",
    "    # each input: 三個維度, rally shot feature\n",
    "    input_others = keras.Input(shape=(rally_size, shot_size, feature_dim[0]))\n",
    "    input_space = keras.Input(shape=(rally_size, shot_size))\n",
    "    input_action = keras.Input(shape=(rally_size, shot_size))\n",
    "\n",
    "    # space & action 先做 embedding, 再和 others concat\n",
    "    embed_space_layer = Embedding(input_dim=feature_dim[1], output_dim=space_embed_size, mask_zero=True, name='Space_Embedding')\n",
    "    embed_action_layer = Embedding(input_dim=feature_dim[2], output_dim=action_embed_size, mask_zero=True, name='Action_Embedding')\n",
    "    masking_layer = Masking(mask_value=0)   # for input_others (還沒有經過mask)\n",
    "    concat_layer = Concatenate(name='Input_Concat')\n",
    "\n",
    "    embed_shot_layer = CNN_with_mask(kernel_size=3, filters=shot_embed_size, strides=3, name='Shot_Embedding')\n",
    "\n",
    "    cnn_layer = CNN_with_mask(kernel_size=3, filters=shot_embed_size, strides=1, name='CNN_Layer')\n",
    "    gru_layer = GRU(units=16, name='GRU_Layer')\n",
    "    dense_layer = Dense(units=2, activation='softmax')\n",
    "\n",
    "    # forward\n",
    "    inputs = [input_others, input_space, input_action]\n",
    "\n",
    "    embed_space = embed_space_layer(input_space)\n",
    "    embed_action = embed_action_layer(input_action)\n",
    "    masked_others = masking_layer(tf.cast(input_others, tf.float32))\n",
    "    embed_input = concat_layer([masked_others, embed_space, embed_action])\n",
    "    embed_shot = tf.squeeze(embed_shot_layer(embed_input), axis=2)\n",
    "\n",
    "    cnn_output = cnn_layer(embed_shot)\n",
    "    gru_output = gru_layer(cnn_output)\n",
    "    output = dense_layer(gru_output)\n",
    "    model = keras.Model(inputs=inputs, outputs=output, name='Classification')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Classification\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 14, 3, 36)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 14, 3, 36)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 14, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 14, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, 14, 3, 36)    0           tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Space_Embedding (Embedding)     (None, 14, 3, 8)     152         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Action_Embedding (Embedding)    (None, 14, 3, 8)     128         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Input_Concat (Concatenate)      (None, 14, 3, 52)    0           masking[0][0]                    \n",
      "                                                                 Space_Embedding[0][0]            \n",
      "                                                                 Action_Embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "cnn_with_mask (CNN_with_mask)   (None, 14, 1, 16)    2512        Input_Concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 14, 16)       0           cnn_with_mask[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cnn_with_mask_1 (CNN_with_mask) (None, 14, 16)       784         tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "GRU_Layer (GRU)                 (None, 16)           1632        cnn_with_mask_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            34          GRU_Layer[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,242\n",
      "Trainable params: 5,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(others_tensor, space_tensor, action_tensor, label_tensor):\n",
    "    l = label_tensor.shape[0]\n",
    "    split_persentage = int(l*0.7)\n",
    "\n",
    "    train_space = space_tensor[:split_persentage]\n",
    "    train_action = action_tensor[:split_persentage]\n",
    "    train_others = others_tensor[:split_persentage]\n",
    "    train_label = label[:split_persentage]\n",
    "\n",
    "    test_space = space_tensor[split_persentage:]\n",
    "    test_action = action_tensor[split_persentage:]\n",
    "    test_others = others_tensor[split_persentage:]\n",
    "    test_label = label[split_persentage:]\n",
    "\n",
    "    train_x = [train_others, train_space, train_action]\n",
    "    train_y = train_label\n",
    "\n",
    "    test_x = [test_others, test_space, test_action]\n",
    "    test_y = test_label\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = split_data(rally_set_tensor, rally_space_set_tensor, rally_action_set_tensor, rally_result_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularizer = tf.keras.regularizers.l2(0.01)\n",
    "optimizer = 'adam'\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "epochs = 30\n",
    "# callbacks = tf.keras.callbacks.EarlyStopping(min_delta=0.002, patience=15, restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "29/29 [==============================] - 2s 5ms/step - loss: 0.6449 - accuracy: 0.6645\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.6656\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.6656\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6356 - accuracy: 0.6656\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6345 - accuracy: 0.6656\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6214 - accuracy: 0.6733\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6077 - accuracy: 0.6932\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.6800: 0s - loss: 0.6015 - accuracy: 0.68\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.5896 - accuracy: 0.6811\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.6888\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.6899\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.6866\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.6822\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7165\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7364\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7685\n",
      "Epoch 17/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8128\n",
      "Epoch 18/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8206\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.8627\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2566 - accuracy: 0.9003\n",
      "Epoch 21/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.8992\n",
      "Epoch 22/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9114\n",
      "Epoch 23/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1823 - accuracy: 0.9302\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1665 - accuracy: 0.9402\n",
      "Epoch 25/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1659 - accuracy: 0.9402\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.9557\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1149 - accuracy: 0.9657\n",
      "Epoch 28/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9690\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9756\n",
      "Epoch 30/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eace05c7b8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6700 - accuracy: 0.8067\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_y_pred = np.argmax(y_pred, axis=1)\n",
    "argmax_test_y = np.argmax(test_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from evaluate import calculate_BS, f1, show_eval_result_2class\n",
    "\n",
    "acc_score = accuracy_score(argmax_test_y, argmax_y_pred)\n",
    "f1_score = f1(argmax_test_y, argmax_y_pred)\n",
    "auc_score = roc_auc_score(test_y, y_pred)\n",
    "BS = calculate_BS(test_y, y_pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:    0.81\n",
      "f1:          0.74\n",
      "auc:         0.90\n",
      "BS:          0.16\n"
     ]
    }
   ],
   "source": [
    "show_eval_result_2class(acc_score, f1_score, auc_score, BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SportScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

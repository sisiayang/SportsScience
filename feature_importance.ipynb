{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from keras.layers import Embedding, Masking, Concatenate, GRU, Dense, Reshape\n",
    "from model import CNN_with_mask\n",
    "\n",
    "from get_training_data import get_rally_result, get_padding_data, permute_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(44)\n",
    "tf.random.set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaced_by_mode(df, ex_feature):\n",
    "    if(ex_feature == 'Original'):\n",
    "        return df\n",
    "    col = ['Team', 'No.', 'Space', 'Action']\n",
    "    col.remove(ex_feature)\n",
    "    for c in col:\n",
    "        mode = df.mode(axis=0)[c][0]\n",
    "        replace = {list(df.groupby(c).groups.keys())[i]: mode for i in range(len(df.groupby(c)))}\n",
    "        df[c] = df[c].replace(replace)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature: Team, No., Space, Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'Action'\n",
    "# df = permute_feature(df, feature)\n",
    "df = replaced_by_mode(df, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_replace = {list(df.groupby('Space').groups.keys())[i]: i+1 for i in range(len(df.groupby('Space')))}\n",
    "action_replace = {list(df.groupby('Action').groups.keys())[i]: i+1 for i in range(len(df.groupby('Action')))}\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Team', 'No.'])\n",
    "df['Space'] = df['Space'].replace(space_replace)\n",
    "df['Action'] = df['Action'].replace(action_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, ignor = get_rally_result(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1291, 2, 3, 2)\n",
      "(1291, 2, 3, 1)\n",
      "(1291, 2, 3, 1)\n",
      "(1291, 2)\n"
     ]
    }
   ],
   "source": [
    "rally_set, rally_space_set, rally_action_set= get_padding_data(df, ignor)\n",
    "\n",
    "# rally數, 最大回合數in one rally, 3, feature數\n",
    "print(rally_set.shape)\n",
    "print(rally_space_set.shape)\n",
    "print(rally_action_set.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_space_set = rally_space_set.squeeze()\n",
    "rally_action_set = rally_action_set.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_set_tensor = tf.convert_to_tensor(rally_set)\n",
    "rally_space_set_tensor = tf.convert_to_tensor(rally_space_set)\n",
    "rally_action_set_tensor = tf.convert_to_tensor(rally_action_set)\n",
    "rally_result_tensor = tf.convert_to_tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_size = rally_set.shape[1]\n",
    "shot_size = 3\n",
    "feature_dim = (rally_set.shape[-1], len(df.groupby('Space'))+1, len(df.groupby('Action'))+1)\n",
    "space_embed_size = 8\n",
    "action_embed_size = 8\n",
    "shot_embed_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size):\n",
    "    '''\n",
    "    framework: \n",
    "    1. 對 space, action 做 embeding, (input, output) = (feature_dim, embed_size)\n",
    "    2. concat space, action, others 成一個 embedded vector for each atk, (input) =  ([feature_dim, embed_size, embed_size])\n",
    "    3. 先做 embedding\n",
    "    4. CNN, filters = shot_embed_size\n",
    "    5. GRU\n",
    "    '''\n",
    "    # each input: 三個維度, rally shot feature\n",
    "    input_others = keras.Input(shape=(rally_size, shot_size, feature_dim[0]))\n",
    "    input_space = keras.Input(shape=(rally_size, shot_size))\n",
    "    input_action = keras.Input(shape=(rally_size, shot_size))\n",
    "\n",
    "    # space & action 先做 embedding, 再和 others concat\n",
    "    embed_space_layer = Embedding(input_dim=feature_dim[1], output_dim=space_embed_size, mask_zero=True, name='Space_Embedding')\n",
    "    embed_action_layer = Embedding(input_dim=feature_dim[2], output_dim=action_embed_size, mask_zero=True, name='Action_Embedding')\n",
    "    masking_layer = Masking(mask_value=0)   # for input_others (還沒有經過mask)\n",
    "    concat_layer = Concatenate(name='Input_Concat')\n",
    "\n",
    "    embed_shot_layer = CNN_with_mask(kernel_size=3, filters=shot_embed_size, strides=3, name='Shot_Embedding')\n",
    "\n",
    "    cnn_layer = CNN_with_mask(kernel_size=3, filters=shot_embed_size, strides=1, name='CNN_Layer')\n",
    "    gru_layer = GRU(units=16, name='GRU_Layer')\n",
    "    dense_layer = Dense(units=2, activation='softmax')\n",
    "\n",
    "    # forward\n",
    "    inputs = [input_others, input_space, input_action]\n",
    "\n",
    "    embed_space = embed_space_layer(input_space)\n",
    "    embed_action = embed_action_layer(input_action)\n",
    "    masked_others = masking_layer(tf.cast(input_others, tf.float32))\n",
    "    embed_input = concat_layer([masked_others, embed_space, embed_action])\n",
    "    embed_shot = tf.squeeze(embed_shot_layer(embed_input), axis=2)\n",
    "\n",
    "    cnn_output = cnn_layer(embed_shot)\n",
    "    gru_output = gru_layer(cnn_output)\n",
    "    output = dense_layer(gru_output)\n",
    "    model = keras.Model(inputs=inputs, outputs=output, name='Classification')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Classification\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2, 3, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 2, 3, 2)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2, 3)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 2, 3)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, 2, 3, 2)      0           tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Space_Embedding (Embedding)     (None, 2, 3, 8)      16          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Action_Embedding (Embedding)    (None, 2, 3, 8)      128         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Input_Concat (Concatenate)      (None, 2, 3, 18)     0           masking[0][0]                    \n",
      "                                                                 Space_Embedding[0][0]            \n",
      "                                                                 Action_Embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "cnn_with_mask (CNN_with_mask)   (None, 2, 1, 16)     880         Input_Concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 2, 16)        0           cnn_with_mask[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cnn_with_mask_1 (CNN_with_mask) (None, 2, 16)        784         tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "GRU_Layer (GRU)                 (None, 16)           1632        cnn_with_mask_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            34          GRU_Layer[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,474\n",
      "Trainable params: 3,474\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(others_tensor, space_tensor, action_tensor, label_tensor):\n",
    "    l = label_tensor.shape[0]\n",
    "    split_persentage = int(l*0.9)\n",
    "\n",
    "    train_space = space_tensor[:split_persentage]\n",
    "    train_action = action_tensor[:split_persentage]\n",
    "    train_others = others_tensor[:split_persentage]\n",
    "    train_label = label[:split_persentage]\n",
    "\n",
    "    test_space = space_tensor[split_persentage:]\n",
    "    test_action = action_tensor[split_persentage:]\n",
    "    test_others = others_tensor[split_persentage:]\n",
    "    test_label = label[split_persentage:]\n",
    "\n",
    "    train_x = [train_others, train_space, train_action]\n",
    "    train_y = train_label\n",
    "\n",
    "    test_x = [test_others, test_space, test_action]\n",
    "    test_y = test_label\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = split_data(rally_set_tensor, rally_space_set_tensor, rally_action_set_tensor, rally_result_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'adam'\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "epochs = 30\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(min_delta=0.002, patience=15, restore_best_weights=True, monitor='val_loss')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33/33 [==============================] - 2s 12ms/step - loss: 0.6072 - accuracy: 0.6638 - val_loss: 0.5299 - val_accuracy: 0.6923\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7826 - val_loss: 0.3470 - val_accuracy: 0.8803\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.2618 - accuracy: 0.8784 - val_loss: 0.1947 - val_accuracy: 0.9573\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1602 - accuracy: 0.9636 - val_loss: 0.1542 - val_accuracy: 0.9658\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9646 - val_loss: 0.1487 - val_accuracy: 0.9744\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9636 - val_loss: 0.1413 - val_accuracy: 0.9744\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.9674 - val_loss: 0.1391 - val_accuracy: 0.9744\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9674 - val_loss: 0.1415 - val_accuracy: 0.9573\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.9713 - val_loss: 0.1353 - val_accuracy: 0.9658\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.9693 - val_loss: 0.1357 - val_accuracy: 0.9573\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9693 - val_loss: 0.1450 - val_accuracy: 0.9487\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9722 - val_loss: 0.1450 - val_accuracy: 0.9487\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9732 - val_loss: 0.1338 - val_accuracy: 0.9658\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9713 - val_loss: 0.1504 - val_accuracy: 0.9487\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9684 - val_loss: 0.1338 - val_accuracy: 0.9573\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9722 - val_loss: 0.1346 - val_accuracy: 0.9573\n",
      "Epoch 17/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9713 - val_loss: 0.1330 - val_accuracy: 0.9573\n",
      "Epoch 18/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9732 - val_loss: 0.1333 - val_accuracy: 0.9573\n",
      "Epoch 19/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9732 - val_loss: 0.1386 - val_accuracy: 0.9573\n",
      "Epoch 20/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1033 - accuracy: 0.9693 - val_loss: 0.1348 - val_accuracy: 0.9658\n",
      "Epoch 21/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9741 - val_loss: 0.1360 - val_accuracy: 0.9573\n",
      "Epoch 22/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.9732 - val_loss: 0.1307 - val_accuracy: 0.9573\n",
      "Epoch 23/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9741 - val_loss: 0.1318 - val_accuracy: 0.9573\n",
      "Epoch 24/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9732 - val_loss: 0.1298 - val_accuracy: 0.9573\n",
      "Epoch 25/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.9741 - val_loss: 0.1343 - val_accuracy: 0.9573\n",
      "Epoch 26/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9761 - val_loss: 0.1295 - val_accuracy: 0.9573\n",
      "Epoch 27/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.9751 - val_loss: 0.1306 - val_accuracy: 0.9573\n",
      "Epoch 28/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9761 - val_loss: 0.1313 - val_accuracy: 0.9573\n",
      "Epoch 29/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9732 - val_loss: 0.1327 - val_accuracy: 0.9573\n",
      "Epoch 30/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.9751 - val_loss: 0.1310 - val_accuracy: 0.9573\n"
     ]
    }
   ],
   "source": [
    "History = model.fit(train_x, train_y, epochs=epochs, validation_split=0.1, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('bestModel/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1329 - accuracy: 0.9692\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_y_pred = np.argmax(y_pred, axis=1)\n",
    "argmax_test_y = np.argmax(test_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from evaluate import calculate_BS, f1, show_eval_result_2class\n",
    "\n",
    "acc_score = accuracy_score(argmax_test_y, argmax_y_pred)\n",
    "f1_score = f1(argmax_test_y, argmax_y_pred)\n",
    "auc_score = roc_auc_score(test_y, y_pred)\n",
    "BS = calculate_BS(test_y, y_pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:    0.97\n",
      "f1:          0.98\n",
      "auc:         0.98\n",
      "BS:          0.03\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:    {:.2f}'.format(acc_score))\n",
    "print('f1:          {:.2f}'.format(f1_score))\n",
    "print('auc:         {:.2f}'.format(auc_score))\n",
    "print('BS:          {:.2f}'.format(BS['BS'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_result(type):\n",
    "    if(type == 'permute'):\n",
    "        output_path = 'permute_feature_result.txt'\n",
    "        f = open(output_path, 'a')\n",
    "        f.write('Permuted feature: ' + feature + '\\n')\n",
    "        f.write('-'*40 + '\\n')\n",
    "        f.write('accuracy:    {:.2f}'.format(acc_score) + '\\n')\n",
    "        f.write('f1:          {:.2f}'.format(f1_score) + '\\n')\n",
    "        f.write('auc:         {:.2f}'.format(auc_score) + '\\n')\n",
    "        f.write('BS:          {:.2f}'.format(BS['BS'][0]) + '\\n')\n",
    "        f.write('\\n' + '='*40 + '\\n')\n",
    "        f.close()\n",
    "    elif(type == 'mode'):\n",
    "        output_path = 'replaced_by_mode_result.txt'\n",
    "        f = open(output_path, 'a')\n",
    "        f.write('Fixed feature: ' + feature + '\\n')\n",
    "        f.write('-'*40 + '\\n')\n",
    "        f.write('accuracy:    {:.2f}'.format(acc_score) + '\\n')\n",
    "        f.write('f1:          {:.2f}'.format(f1_score) + '\\n')\n",
    "        f.write('auc:         {:.2f}'.format(auc_score) + '\\n')\n",
    "        f.write('BS:          {:.2f}'.format(BS['BS'][0]) + '\\n')\n",
    "        f.write('\\n' + '='*40 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_result('permute')\n",
    "output_result('mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SportsScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from keras.layers import Embedding, Masking, Concatenate, GRU, Dense, Reshape\n",
    "from model import CNN_with_mask\n",
    "\n",
    "from get_training_data import get_rally_result, get_padding_data, permute_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(44)\n",
    "tf.random.set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def replaced_by_mode(df, ex_feature):\n",
    "#     if(ex_feature == 'Original'):\n",
    "#         return df\n",
    "#     col = ['Team', 'No.', 'Space', 'Action']\n",
    "#     col.remove(ex_feature)\n",
    "#     for c in col:\n",
    "#         mode = df.mode(axis=0)[c][0]\n",
    "#         replace = {list(df.groupby(c).groups.keys())[i]: mode for i in range(len(df.groupby(c)))}\n",
    "#         df[c] = df[c].replace(replace)\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature: Team, No., Space, Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [['Player', 'Space'], ['Player', 'Action'], ['Player', 'Sequence'], ['Space', 'Action'], ['Space', 'Sequence'], ['Action', 'Sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Game  Rally  Player Team Space Action  Errors  Nothing  Score\n",
      "0    21   25.0   ITA_6  USA     6   JS_0     NaN      1.0    NaN\n",
      "1    21   25.0  ITA_15  BRA     1    R_0     NaN      1.0    NaN\n",
      "2    21   25.0   USA_2  BRA     6    G_0     NaN      1.0    NaN\n",
      "3    21   25.0   ITA_6  BRA     2    A_0     NaN      NaN    1.0\n",
      "4    21   25.0   ITA_5  USA     5    D_0     1.0      NaN    NaN\n",
      "   Game  Rally  Player Team Space Action  Errors  Nothing  Score\n",
      "0    21   25.0  ITA_15  USA     6    D_0     NaN      1.0    NaN\n",
      "1    21   25.0  POL_19  BRA     1    A_0     NaN      1.0    NaN\n",
      "2    21   25.0   ITA_6  BRA     6    R_0     NaN      1.0    NaN\n",
      "3    21   25.0  FRA_19  BRA     2    G_1     NaN      NaN    1.0\n",
      "4    21   25.0  FRA_19  USA     5    R_1     1.0      NaN    NaN\n",
      "  Game  Rally  Player Team Space Action  Errors  Nothing  Score\n",
      "0   14    6.0   ITA_7  POL     1   At_0     1.0      NaN    NaN\n",
      "0   21   15.0   NED_7  BRA     Y   JS_0     NaN      1.0    NaN\n",
      "1   21   15.0  FRA_14  BRA     7    R_0     NaN      1.0    NaN\n",
      "2   21   15.0  FRA_17  BRA     3    B_0     NaN      1.0    NaN\n",
      "3   21   15.0  POL_19  USA     2    G_1     NaN      1.0    NaN\n",
      "  Game  Rally  Player Team Space Action  Errors  Nothing  Score\n",
      "0   14    6.0   ITA_7  POL     1    A_0     1.0      NaN    NaN\n",
      "0   21   15.0   NED_7  BRA     1    A_0     NaN      1.0    NaN\n",
      "1   21   15.0  FRA_14  BRA     6    R_0     NaN      1.0    NaN\n",
      "2   21   15.0  FRA_17  BRA     6    R_0     NaN      1.0    NaN\n",
      "3   21   15.0  POL_19  USA     4    D_0     NaN      1.0    NaN\n",
      "  Game  Rally  Player Team Space Action  Errors  Nothing  Score\n",
      "0   25    7.0  BRA_17  USA     L   FS_0     NaN      1.0    NaN\n",
      "1   25    7.0   NED_2  USA     L    D_0     NaN      1.0    NaN\n",
      "2   25    7.0   IRI_1  USA     6    A_0     NaN      1.0    NaN\n",
      "3   25    7.0  ITA_15  FRA     4    R_1     NaN      1.0    NaN\n",
      "4   25    7.0  FRA_17  FRA     6    G_1     NaN      1.0    NaN\n",
      "  Game  Rally  Player Team Space Action  Errors  Nothing  Score\n",
      "0   28   44.0   POL_7  POL     1    A_0     1.0      NaN    NaN\n",
      "1   28   44.0  ITA_17  POL     1   FS_0     NaN      1.0    NaN\n",
      "2   28   44.0  USA_11  POL     4    A_0     NaN      1.0    NaN\n",
      "3   28   44.0   JAP_8  POL     2   FS_0     NaN      1.0    NaN\n",
      "4   28   44.0   BRA_1  USA     L    R_0     NaN      1.0    NaN\n"
     ]
    }
   ],
   "source": [
    "for experiment in feature_list:\n",
    "    ############# permutation #############################\n",
    "    for f in experiment:\n",
    "        df = permute_feature(df, f)\n",
    "    ############# train for result ########################\n",
    "    model = training(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_1 = 'Space'\n",
    "feature_2 = 'Player'\n",
    "df = permute_feature(df, feature_1)\n",
    "df = permute_feature(df, feature_2)\n",
    "\n",
    "# df = replaced_by_mode(df, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Rally</th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Space</th>\n",
       "      <th>Action</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Nothing</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>25.0</td>\n",
       "      <td>USA_15</td>\n",
       "      <td>USA</td>\n",
       "      <td>Y</td>\n",
       "      <td>JS_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>25.0</td>\n",
       "      <td>BRA_18</td>\n",
       "      <td>BRA</td>\n",
       "      <td>7</td>\n",
       "      <td>R_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>25.0</td>\n",
       "      <td>BRA_1</td>\n",
       "      <td>BRA</td>\n",
       "      <td>2</td>\n",
       "      <td>G_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>25.0</td>\n",
       "      <td>BRA_23</td>\n",
       "      <td>BRA</td>\n",
       "      <td>2</td>\n",
       "      <td>A_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>25.0</td>\n",
       "      <td>USA_8</td>\n",
       "      <td>USA</td>\n",
       "      <td>8</td>\n",
       "      <td>D_0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Game  Rally  Player Team Space Action  Errors  Nothing  Score\n",
       "0    21   25.0  USA_15  USA     Y   JS_0     NaN      1.0    NaN\n",
       "1    21   25.0  BRA_18  BRA     7    R_0     NaN      1.0    NaN\n",
       "2    21   25.0   BRA_1  BRA     2    G_0     NaN      1.0    NaN\n",
       "3    21   25.0  BRA_23  BRA     2    A_0     NaN      NaN    1.0\n",
       "4    21   25.0   USA_8  USA     8    D_0     1.0      NaN    NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(df):\n",
    "    space_replace = {list(df.groupby('Space').groups.keys())[i]: i+1 for i in range(len(df.groupby('Space')))}\n",
    "    action_replace = {list(df.groupby('Action').groups.keys())[i]: i+1 for i in range(len(df.groupby('Action')))}\n",
    "    df = pd.get_dummies(df, columns=['Player'])\n",
    "    df = df.replace(space_replace)\n",
    "    df = df.replace(action_replace)\n",
    "    # get label\n",
    "    label, ignor = get_rally_result(df)\n",
    "    # get training data\n",
    "    rally_set, rally_space_set, rally_action_set= get_padding_data(df, ignor)\n",
    "    rally_space_set = rally_space_set.squeeze()\n",
    "    rally_action_set = rally_action_set.squeeze()\n",
    "    rally_set_tensor = tf.convert_to_tensor(rally_set)\n",
    "    rally_space_set_tensor = tf.convert_to_tensor(rally_space_set)\n",
    "    rally_action_set_tensor = tf.convert_to_tensor(rally_action_set)\n",
    "    rally_result_tensor = tf.convert_to_tensor(label)\n",
    "\n",
    "    train_x, train_y, test_x, test_y = split_data(rally_set_tensor, rally_space_set_tensor, rally_action_set_tensor, rally_result_tensor)\n",
    "    # setting\n",
    "    rally_size = rally_set.shape[1]\n",
    "    shot_size = 3\n",
    "    feature_dim = (rally_set.shape[-1], len(df.groupby('Space'))+1, len(df.groupby('Action'))+1)\n",
    "    space_embed_size = 8\n",
    "    action_embed_size = 8\n",
    "    shot_embed_size = 16\n",
    "    # create model\n",
    "    model = create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size)\n",
    "    optimizer = 'adam'\n",
    "    loss = keras.losses.CategoricalCrossentropy()\n",
    "    metrics = ['accuracy']\n",
    "    epochs = 30\n",
    "    callbacks = tf.keras.callbacks.EarlyStopping(min_delta=0.002, patience=15, restore_best_weights=True, monitor='val_loss')\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    model.fit(train_x, train_y, epochs=epochs, validation_split=0.1, callbacks=[callbacks])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_replace = {list(df.groupby('Space').groups.keys())[i]: i+1 for i in range(len(df.groupby('Space')))}\n",
    "action_replace = {list(df.groupby('Action').groups.keys())[i]: i+1 for i in range(len(df.groupby('Action')))}\n",
    "\n",
    "# df = pd.get_dummies(df, columns=['Team', 'No.'])\n",
    "df = pd.get_dummies(df, columns=['Player'])\n",
    "df = df.replace(space_replace)\n",
    "df = df.replace(action_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, ignor = get_rally_result(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1291, 19, 3, 127)\n",
      "(1291, 19, 3, 1)\n",
      "(1291, 19, 3, 1)\n",
      "(1291, 2)\n"
     ]
    }
   ],
   "source": [
    "rally_set, rally_space_set, rally_action_set= get_padding_data(df, ignor)\n",
    "\n",
    "# rally數, 最大回合數in one rally, 3, feature數\n",
    "print(rally_set.shape)\n",
    "print(rally_space_set.shape)\n",
    "print(rally_action_set.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_space_set = rally_space_set.squeeze()\n",
    "rally_action_set = rally_action_set.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_set_tensor = tf.convert_to_tensor(rally_set)\n",
    "rally_space_set_tensor = tf.convert_to_tensor(rally_space_set)\n",
    "rally_action_set_tensor = tf.convert_to_tensor(rally_action_set)\n",
    "rally_result_tensor = tf.convert_to_tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqWeightedAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestAttention(keras.layers.Layer):\n",
    "    def __init__(self, input_dim=32):\n",
    "        super().__init__()\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_dim, input_dim), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "        self.b = self.add_weight(shape=(input_dim,), initializer=\"random_normal\", trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Hadamard product\n",
    "        product_x = tf.matmul(inputs, self.w) + self.b\n",
    "        soft_x = tf.nn.softmax(product_x)\n",
    "        output = tf.multiply(inputs, soft_x)\n",
    "        return output\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'con_layer': self.con_layer\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rally_num = rally_set.shape[0]\n",
    "rally_size = rally_set.shape[1]\n",
    "shot_size = 3\n",
    "feature_dim = (rally_set.shape[-1], len(df.groupby('Space'))+1, len(df.groupby('Action'))+1)\n",
    "space_embed_size = 8\n",
    "action_embed_size = 8\n",
    "shot_embed_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size):\n",
    "    '''\n",
    "    framework: \n",
    "    1. 對 space, action 做 embeding, (input, output) = (feature_dim, embed_size)\n",
    "    2. concat space, action, others 成一個 embedded vector for each atk, (input) =  ([feature_dim, embed_size, embed_size])\n",
    "    3. 先做 embedding\n",
    "    4. CNN, filters = shot_embed_size\n",
    "    5. GRU\n",
    "    '''\n",
    "    # each input: 三個維度, rally shot feature\n",
    "    input_others = keras.Input(shape=(rally_size, shot_size, feature_dim[0]))\n",
    "    input_space = keras.Input(shape=(rally_size, shot_size))\n",
    "    input_action = keras.Input(shape=(rally_size, shot_size))\n",
    "\n",
    "    # space & action 先做 embedding, 再和 others concat\n",
    "    embed_space_layer = Embedding(input_dim=feature_dim[1], output_dim=space_embed_size, mask_zero=True, name='Space_Embedding')\n",
    "    embed_action_layer = Embedding(input_dim=feature_dim[2], output_dim=action_embed_size, mask_zero=True, name='Action_Embedding')\n",
    "    masking_layer = Masking(mask_value=0)\n",
    "    concat_layer = Concatenate(name='Input_Concat')\n",
    "\n",
    "    attention_layer = TestAttention(input_dim=feature_dim[0]+space_embed_size+action_embed_size)\n",
    "\n",
    "    embed_shot_layer = CNN_with_mask(kernel_size=3, filters=shot_embed_size, strides=3, name='Shot_Embedding')\n",
    "    cnn_layer = CNN_with_mask(kernel_size=3, filters=shot_embed_size, strides=1, name='CNN_Layer')\n",
    "    gru_layer = GRU(units=16, name='GRU_Layer')\n",
    "\n",
    "    # gru_layer = GRU(return_sequences=True, units=16, name='GRU_Layer')\n",
    "    # layer_attention = SeqWeightedAttention(return_attention=True)\n",
    "\n",
    "    dense_layer = Dense(units=2, activation='softmax')\n",
    "\n",
    "    # forward\n",
    "    inputs = [input_others, input_space, input_action]\n",
    "\n",
    "    embed_space = embed_space_layer(input_space)\n",
    "    embed_action = embed_action_layer(input_action)\n",
    "    masked_others = masking_layer(tf.cast(input_others, tf.float32))\n",
    "    embed_input = concat_layer([masked_others, embed_space, embed_action])\n",
    "\n",
    "    attention_input = attention_layer(embed_input)\n",
    "    embed_shot = tf.squeeze(embed_shot_layer(attention_input), axis=2)\n",
    "\n",
    "    # embed_shot = tf.squeeze(embed_shot_layer(embed_input), axis=2)\n",
    "\n",
    "    cnn_output = cnn_layer(embed_shot)\n",
    "    gru_output = gru_layer(cnn_output)\n",
    "\n",
    "    # rally_represent, contributions = layer_attention(gru_output)\n",
    "    # output = dense_layer(rally_represent)\n",
    "\n",
    "    output = dense_layer(gru_output)\n",
    "    model = keras.Model(inputs=inputs, outputs=output, name='Classification')\n",
    "\n",
    "    # model_attention = tf.keras.Model(inputs=inputs, outputs=contributions, name='Attention')\n",
    "    # return model, model_attention\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Classification\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 19, 3, 127)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 19, 3, 127)   0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 19, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 19, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, 19, 3, 127)   0           tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Space_Embedding (Embedding)     (None, 19, 3, 8)     152         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Action_Embedding (Embedding)    (None, 19, 3, 8)     128         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Input_Concat (Concatenate)      (None, 19, 3, 143)   0           masking[0][0]                    \n",
      "                                                                 Space_Embedding[0][0]            \n",
      "                                                                 Action_Embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "test_attention (TestAttention)  (None, 19, 3, 143)   20592       Input_Concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "cnn_with_mask (CNN_with_mask)   (None, 19, 1, 16)    6880        test_attention[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 19, 16)       0           cnn_with_mask[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cnn_with_mask_1 (CNN_with_mask) (None, 19, 16)       784         tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "GRU_Layer (GRU)                 (None, 16)           1632        cnn_with_mask_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            34          GRU_Layer[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 30,202\n",
      "Trainable params: 30,202\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model, model_attention = create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size)\n",
    "model = create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(others_tensor, space_tensor, action_tensor, label_tensor):\n",
    "    l = label_tensor.shape[0]\n",
    "    split_persentage = int(l*0.9)\n",
    "\n",
    "    train_space = space_tensor[:split_persentage]\n",
    "    train_action = action_tensor[:split_persentage]\n",
    "    train_others = others_tensor[:split_persentage]\n",
    "    train_label = label[:split_persentage]\n",
    "\n",
    "    test_space = space_tensor[split_persentage:]\n",
    "    test_action = action_tensor[split_persentage:]\n",
    "    test_others = others_tensor[split_persentage:]\n",
    "    test_label = label[split_persentage:]\n",
    "\n",
    "    train_x = [train_others, train_space, train_action]\n",
    "    train_y = train_label\n",
    "\n",
    "    test_x = [test_others, test_space, test_action]\n",
    "    test_y = test_label\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = split_data(rally_set_tensor, rally_space_set_tensor, rally_action_set_tensor, rally_result_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'adam'\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "epochs = 30\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(min_delta=0.002, patience=15, restore_best_weights=True, monitor='val_loss')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_before = model.layers[8].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33/33 [==============================] - 3s 43ms/step - loss: 0.6564 - accuracy: 0.6513 - val_loss: 0.6039 - val_accuracy: 0.7094\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.6428 - accuracy: 0.6600 - val_loss: 0.6074 - val_accuracy: 0.7094\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.6433 - accuracy: 0.6600 - val_loss: 0.6079 - val_accuracy: 0.7094\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.6434 - accuracy: 0.6600 - val_loss: 0.6153 - val_accuracy: 0.7094acy: 0.\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.6424 - accuracy: 0.6600 - val_loss: 0.6085 - val_accuracy: 0.7094\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.6418 - accuracy: 0.6600 - val_loss: 0.6083 - val_accuracy: 0.7094\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.6416 - accuracy: 0.6600 - val_loss: 0.6112 - val_accuracy: 0.7094\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.6418 - accuracy: 0.6600 - val_loss: 0.6085 - val_accuracy: 0.7094\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.6440 - accuracy: 0.6600 - val_loss: 0.6053 - val_accuracy: 0.7094\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 1s 31ms/step - loss: 0.6413 - accuracy: 0.6600 - val_loss: 0.6104 - val_accuracy: 0.7094\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.6423 - accuracy: 0.6600 - val_loss: 0.6103 - val_accuracy: 0.7094\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.6428 - accuracy: 0.6600 - val_loss: 0.6062 - val_accuracy: 0.7094\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.6427 - accuracy: 0.6600 - val_loss: 0.6062 - val_accuracy: 0.7094\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.6415 - accuracy: 0.6600 - val_loss: 0.6083 - val_accuracy: 0.7094\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 1s 32ms/step - loss: 0.6426 - accuracy: 0.6600 - val_loss: 0.6119 - val_accuracy: 0.7094\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 1s 33ms/step - loss: 0.6423 - accuracy: 0.6600 - val_loss: 0.6093 - val_accuracy: 0.7094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ee6b7e208>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=epochs, validation_split=0.1, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_after = model.layers[8].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.08376861, -0.02498179,  0.01047854, ...,  0.02681371,\n",
       "          0.02562301, -0.06401526],\n",
       "        [-0.03941688,  0.04270202,  0.03665999, ..., -0.00363697,\n",
       "         -0.05034636, -0.07477298],\n",
       "        [ 0.0118912 , -0.02306752, -0.04930489, ..., -0.0185284 ,\n",
       "         -0.01278042,  0.00308417],\n",
       "        ...,\n",
       "        [-0.06258168,  0.00010242, -0.07988643, ..., -0.03355335,\n",
       "         -0.01033681,  0.03377532],\n",
       "        [-0.0313025 ,  0.008078  ,  0.0051798 , ..., -0.07341696,\n",
       "         -0.01812319,  0.04320578],\n",
       "        [ 0.02175593,  0.02106545,  0.04403274, ...,  0.01319378,\n",
       "         -0.09671459,  0.0850658 ]], dtype=float32),\n",
       " array([ 0.03038953, -0.00412433, -0.05329286,  0.05852119, -0.04122451,\n",
       "        -0.04798507, -0.03668237,  0.04034596,  0.00456961,  0.06420854,\n",
       "        -0.01609483, -0.04263012, -0.07461799,  0.02536712,  0.10310935,\n",
       "         0.03627792,  0.02991605, -0.01822895, -0.02892245, -0.01732142,\n",
       "         0.09463563, -0.00974691,  0.02731829,  0.08886766,  0.01450706,\n",
       "         0.0125112 , -0.01842144,  0.04595799,  0.04364319,  0.05335183,\n",
       "        -0.05386141,  0.11683808, -0.0155954 ,  0.04833368, -0.07720906,\n",
       "        -0.01906275, -0.02380627, -0.01077974, -0.06216912, -0.024482  ,\n",
       "        -0.00808238,  0.00917959,  0.00428568,  0.11075633, -0.00734478,\n",
       "        -0.05530686,  0.1192269 ,  0.10023247, -0.06794053, -0.05107432,\n",
       "         0.00164581, -0.04487954,  0.072887  ,  0.01569293, -0.03622983,\n",
       "        -0.05581949, -0.05643002, -0.03765314,  0.00549202,  0.01452787,\n",
       "         0.03066283, -0.03324933,  0.0326669 , -0.11664893,  0.01993755,\n",
       "         0.08004091,  0.09426066,  0.03535937,  0.05553409, -0.00686852,\n",
       "         0.06576943, -0.01894825, -0.10087698,  0.04160891,  0.0467568 ,\n",
       "         0.00193341, -0.03689711, -0.02629724, -0.06774657,  0.05389777,\n",
       "        -0.00634624, -0.00831265,  0.01914156,  0.06857371, -0.060237  ,\n",
       "         0.04675036,  0.01924654, -0.05891303,  0.02522176, -0.02528285,\n",
       "         0.02239474,  0.00027125,  0.0027067 ,  0.01804809,  0.0026652 ,\n",
       "         0.00746428, -0.02791939,  0.01850021,  0.04528898, -0.01280685,\n",
       "         0.03513419,  0.07095858,  0.00537938,  0.09625012, -0.0696842 ,\n",
       "        -0.02216096,  0.06761708,  0.06474947, -0.02468121, -0.07657667,\n",
       "        -0.00340387, -0.01101655, -0.03777594,  0.10593557, -0.08597583,\n",
       "        -0.00445653, -0.0428866 ,  0.00795418, -0.05726618,  0.04009149,\n",
       "         0.03975331,  0.02185807,  0.05064794,  0.0141429 , -0.04760962,\n",
       "        -0.04112229,  0.03313098, -0.02829286, -0.04843006, -0.02404494,\n",
       "        -0.07799821, -0.00823745, -0.04462923, -0.00623854, -0.00228738,\n",
       "         0.11951077, -0.07623936, -0.04917258,  0.03553827,  0.06941039,\n",
       "        -0.05576092,  0.01679428, -0.0050167 ], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-8.3777115e-02, -2.4981635e-02,  1.0478684e-02, ...,\n",
       "          2.6812842e-02,  2.5626628e-02, -6.4017192e-02],\n",
       "        [-3.9416879e-02,  4.2704612e-02,  3.6659990e-02, ...,\n",
       "         -3.6369511e-03, -5.0346646e-02, -7.4772686e-02],\n",
       "        [ 1.1890503e-02, -2.3068180e-02, -4.9203645e-02, ...,\n",
       "         -1.8528562e-02, -1.2782124e-02,  3.0815790e-03],\n",
       "        ...,\n",
       "        [-6.2711060e-02, -2.2008362e-05, -8.0006540e-02, ...,\n",
       "         -3.1670142e-02, -1.0778417e-02,  3.3656135e-02],\n",
       "        [-3.1279765e-02,  8.1023788e-03,  5.2039437e-03, ...,\n",
       "         -7.3896296e-02, -1.8020695e-02,  4.3219458e-02],\n",
       "        [ 2.1656835e-02,  2.0967864e-02,  4.3943491e-02, ...,\n",
       "          1.4978664e-02, -9.7223982e-02,  8.4818408e-02]], dtype=float32),\n",
       " array([ 2.62037441e-02, -8.23846459e-03, -5.72149456e-02,  5.42457141e-02,\n",
       "        -4.52381074e-02, -5.19731306e-02, -4.07205746e-02,  3.61477248e-02,\n",
       "         4.47482802e-04,  5.98933138e-02, -2.00890191e-02, -4.66553010e-02,\n",
       "        -7.85864517e-02,  2.13944409e-02,  9.87296999e-02,  3.21101062e-02,\n",
       "         2.57119089e-02, -2.22707409e-02, -3.29798311e-02, -2.14359742e-02,\n",
       "         9.01705623e-02, -1.38275605e-02,  2.31435206e-02,  8.44259411e-02,\n",
       "         1.03381202e-02,  8.35984573e-03, -2.24760491e-02,  4.16962057e-02,\n",
       "         3.94017398e-02,  4.91000935e-02, -5.78938089e-02,  1.12496518e-01,\n",
       "        -1.96878575e-02,  4.40573804e-02, -8.11555535e-02, -2.31217667e-02,\n",
       "        -2.78392937e-02, -1.48529299e-02, -6.61305189e-02, -2.85452995e-02,\n",
       "        -1.21837389e-02,  5.02604106e-03,  8.58344720e-05,  1.06338620e-01,\n",
       "        -1.14667835e-02, -5.78762628e-02,  1.13900885e-01,  9.39275324e-02,\n",
       "        -7.18616471e-02, -5.50843105e-02, -2.51149153e-03, -4.88833711e-02,\n",
       "         6.85542822e-02,  1.15204807e-02, -4.02367078e-02, -5.97529039e-02,\n",
       "        -5.68618439e-02, -4.15533595e-02,  1.35932001e-03,  1.03961322e-02,\n",
       "         2.65610423e-02, -3.72809358e-02,  2.84719598e-02, -1.20437391e-01,\n",
       "         1.57295894e-02,  7.57097304e-02,  8.99189189e-02,  3.11215110e-02,\n",
       "         5.12345433e-02, -1.09816883e-02,  6.14758842e-02, -2.30936278e-02,\n",
       "        -1.04744941e-01,  3.73797528e-02,  4.24517505e-02, -2.18209228e-03,\n",
       "        -4.09083068e-02, -3.04535963e-02, -7.17122778e-02,  4.95809615e-02,\n",
       "        -1.04369018e-02, -1.24141900e-02,  1.49831390e-02,  6.41780272e-02,\n",
       "        -6.41956329e-02,  4.24785130e-02,  1.51080498e-02, -6.29716367e-02,\n",
       "         2.10946146e-02, -3.01121287e-02,  1.70570798e-02, -3.84368584e-03,\n",
       "        -1.61360588e-03,  1.38781825e-02,  1.81497051e-03,  3.38845653e-03,\n",
       "        -3.19744013e-02,  1.43191982e-02,  4.10470925e-02, -1.66156478e-02,\n",
       "         3.09200212e-02,  6.66481405e-02,  1.26801431e-03,  9.18629542e-02,\n",
       "        -7.36103803e-02, -2.62208395e-02,  6.33152947e-02,  6.04972579e-02,\n",
       "        -2.87650134e-02, -8.04995820e-02, -7.52992881e-03, -1.51147740e-02,\n",
       "        -4.18443605e-02,  1.01544514e-01, -8.98262784e-02, -8.54915101e-03,\n",
       "        -4.68703397e-02,  3.81352962e-03, -6.12394474e-02,  3.58199701e-02,\n",
       "         3.55431475e-02,  1.76970735e-02,  4.63868417e-02,  1.00256782e-02,\n",
       "        -5.15877344e-02, -4.51869480e-02,  2.88949981e-02, -1.07234893e-02,\n",
       "        -3.46042402e-02, -3.73437293e-02, -9.15485919e-02,  6.38836715e-03,\n",
       "        -5.67823648e-02,  8.12595710e-03,  1.59625113e-02,  1.06798194e-01,\n",
       "        -6.10266030e-02, -3.12455427e-02,  4.75084074e-02,  5.46724685e-02,\n",
       "        -4.02636565e-02,  6.39321795e-03, -7.01322127e-03], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gradients_v2() missing 1 required positional argument: 'xs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-db858770bcd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_before\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: gradients_v2() missing 1 required positional argument: 'xs'"
     ]
    }
   ],
   "source": [
    "tf.gradients(weight_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.diag(model.weights[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('bestModel/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6234 - accuracy: 0.6846\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_y_pred = np.argmax(y_pred, axis=1)\n",
    "argmax_test_y = np.argmax(test_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from evaluate import calculate_BS, f1\n",
    "\n",
    "acc_score = accuracy_score(argmax_test_y, argmax_y_pred)\n",
    "f1_score = f1(argmax_test_y, argmax_y_pred)\n",
    "auc_score = roc_auc_score(test_y, y_pred)\n",
    "BS = calculate_BS(test_y, y_pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:    0.68\n",
      "f1:          0.00\n",
      "auc:         0.52\n",
      "BS:          0.22\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:    {:.2f}'.format(acc_score))\n",
    "print('f1:          {:.2f}'.format(f1_score))\n",
    "print('auc:         {:.2f}'.format(auc_score))\n",
    "print('BS:          {:.2f}'.format(BS['BS'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_result(type, feature_list):\n",
    "    if(type == 'permute'):\n",
    "        output_path = 'permute_feature_result.txt'\n",
    "        f = open(output_path, 'a')\n",
    "        f.write('Permuted feature: ' + str(feature_list) + '\\n')\n",
    "        f.write('-'*40 + '\\n')\n",
    "        f.write('accuracy:    {:.2f}'.format(acc_score) + '\\n')\n",
    "        f.write('f1:          {:.2f}'.format(f1_score) + '\\n')\n",
    "        f.write('auc:         {:.2f}'.format(auc_score) + '\\n')\n",
    "        f.write('BS:          {:.2f}'.format(BS['BS'][0]) + '\\n')\n",
    "        f.write('\\n' + '='*40 + '\\n')\n",
    "        f.close()\n",
    "    elif(type == 'mode'):\n",
    "        output_path = 'replaced_by_mode_result.txt'\n",
    "        f = open(output_path, 'a')\n",
    "        f.write('Fixed feature: ' + str(feature_list) + '\\n')\n",
    "        f.write('-'*40 + '\\n')\n",
    "        f.write('accuracy:    {:.2f}'.format(acc_score) + '\\n')\n",
    "        f.write('f1:          {:.2f}'.format(f1_score) + '\\n')\n",
    "        f.write('auc:         {:.2f}'.format(auc_score) + '\\n')\n",
    "        f.write('BS:          {:.2f}'.format(BS['BS'][0]) + '\\n')\n",
    "        f.write('\\n' + '='*40 + '\\n')\n",
    "    elif(type == 'attention'):\n",
    "        output_path = 'attention_result.txt'\n",
    "        f = open(output_path, 'a')\n",
    "        f.write('Permuted feature: ' + str(feature_list) + '\\n')\n",
    "        f.write('-'*40 + '\\n')\n",
    "        f.write('accuracy:    {:.2f}'.format(acc_score) + '\\n')\n",
    "        f.write('f1:          {:.2f}'.format(f1_score) + '\\n')\n",
    "        f.write('auc:         {:.2f}'.format(auc_score) + '\\n')\n",
    "        f.write('BS:          {:.2f}'.format(BS['BS'][0]) + '\\n')\n",
    "        f.write('\\n' + '='*40 + '\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_result('permute', [feature_1, feature_2])\n",
    "# output_result('mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SportsScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

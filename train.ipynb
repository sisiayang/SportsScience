{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from keras.layers import Embedding, Masking, Concatenate, GRU, Dense, Reshape\n",
    "from model import CNN_with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding_data(df):\n",
    "    '''\n",
    "    one df represents one game\n",
    "    split: space, action, player(?), error&score\n",
    "    label: 發球方是否得分？\n",
    "    '''\n",
    "    col = df.columns\n",
    "    space_col = [c for c in df.columns if 'Space' in c]\n",
    "    action_col = [c for c in df.columns if 'Action' in c]\n",
    "    result_col = ['Errors', 'Score', 'Nothing']\n",
    "    others_col = [c for c in df.columns if c not in space_col and c not in action_col and c not in result_col and c != 'Game' and c != 'Rally']\n",
    "\n",
    "    team_col = [c for c in df.columns if 'Team' in c]\n",
    "\n",
    "    rally_set = []\n",
    "    rally_space_set = []\n",
    "    rally_action_set = []\n",
    "    rally_result_set = []\n",
    "    for _, df_rally in df.groupby(['Game', 'Rally']):   # each rally in one game\n",
    "        # print(df_rally)\n",
    "        curr_team = df.iloc[df_rally.index[0]][team_col].tolist()\n",
    "        shot_set = []\n",
    "        shot_space_set = []\n",
    "        shot_action_set = []\n",
    "        shot_result_set = []\n",
    "        \n",
    "        atk_sequence = []\n",
    "        atk_space_sequence = []\n",
    "        atk_action_sequence = []\n",
    "        atk_result = []\n",
    "        \n",
    "        for _, shot in df_rally.iterrows():\n",
    "            if(shot[team_col].tolist() != curr_team):\n",
    "                shot_set.append(atk_sequence)\n",
    "                shot_space_set.append(atk_space_sequence)\n",
    "                shot_action_set.append(atk_action_sequence)\n",
    "                shot_result_set.append(atk_result)   # 最後一動的結果 -> predict object\n",
    "                \n",
    "                curr_team = shot[team_col].tolist()\n",
    "\n",
    "                atk_sequence = []\n",
    "                atk_space_sequence = []\n",
    "                atk_action_sequence = []\n",
    "\n",
    "            atk_space_sequence.append(shot[space_col])\n",
    "            atk_action_sequence.append(shot[action_col])\n",
    "            atk_sequence.append(shot[others_col])\n",
    "            atk_result = shot[result_col]\n",
    "        \n",
    "        # the last shot\n",
    "        shot_set.append(atk_sequence)\n",
    "        shot_space_set.append(atk_space_sequence)\n",
    "        shot_action_set.append(atk_action_sequence)\n",
    "        shot_result_set.append(atk_result)\n",
    "\n",
    "        # one rally has been finished\n",
    "        shot_set = pad_sequences(shot_set, maxlen=3, padding='post')\n",
    "        shot_space_set = pad_sequences(shot_space_set, maxlen=3, padding='post')\n",
    "        shot_action_set = pad_sequences(shot_action_set, maxlen=3, padding='post')\n",
    "\n",
    "        # one rally has been finished\n",
    "        rally_set.append(shot_set)\n",
    "        rally_space_set.append(shot_space_set)\n",
    "        rally_action_set.append(shot_action_set)\n",
    "        rally_result_set.append(shot_result_set)\n",
    "\n",
    "    padded_rally_set = pad_sequences(rally_set, dtype=float, padding='post')\n",
    "    padded_rally_space_set = pad_sequences(rally_space_set, dtype=float, padding='post')\n",
    "    padded_rally_action_set = pad_sequences(rally_action_set, dtype=float, padding='post')\n",
    "    padded_rally_result_set = pad_sequences(rally_result_set, dtype=float, padding='post')\n",
    "    \n",
    "    return padded_rally_set, padded_rally_space_set, padded_rally_action_set, padded_rally_result_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "\n",
    "space_replace = {list(df.groupby('Space').groups.keys())[i]: i+1 for i in range(len(df.groupby('Space')))}\n",
    "action_replace = {list(df.groupby('Action').groups.keys())[i]: i+1 for i in range(len(df.groupby('Action')))}\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Team', 'No.'])\n",
    "df = df.replace(space_replace)\n",
    "df = df.replace(action_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1292, 14, 3, 36)\n",
      "(1292, 14, 3, 1)\n",
      "(1292, 14, 3, 1)\n",
      "(1292, 14, 3)\n"
     ]
    }
   ],
   "source": [
    "rally_set, rally_space_set, rally_action_set, rally_result_set = get_padding_data(df)\n",
    "\n",
    "# rally數, 最大回合數in one rally, 3, feature數\n",
    "print(rally_set.shape)\n",
    "print(rally_space_set.shape)\n",
    "print(rally_action_set.shape)\n",
    "print(rally_result_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_space_set = rally_space_set.squeeze()\n",
    "rally_action_set = rally_action_set.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_set_tensor = tf.convert_to_tensor(rally_set)\n",
    "rally_space_set_tensor = tf.convert_to_tensor(rally_space_set)\n",
    "rally_action_set_tensor = tf.convert_to_tensor(rally_action_set)\n",
    "rally_result_set_tensor = tf.convert_to_tensor(rally_result_set)\n",
    "\n",
    "rally_result_set_tensor = tf.where(tf.math.is_nan(rally_result_set_tensor), 0.0, rally_result_set_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rally_num = rally_set.shape[0]\n",
    "rally_size = rally_set.shape[1]\n",
    "shot_size = 3\n",
    "feature_dim = (rally_set.shape[-1], len(df.groupby('Space'))+1, len(df.groupby('Action'))+1)\n",
    "space_embed_size = 8\n",
    "action_embed_size = 8\n",
    "shot_embed_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size):\n",
    "    '''\n",
    "    framework: \n",
    "    1. 對 space, action 做 embeding, (input, output) = (feature_dim, embed_size)\n",
    "    2. concat space, action, others 成一個 embedded vector for each atk, (input) =  ([feature_dim, embed_size, embed_size])\n",
    "    3. 先做 embedding\n",
    "    4. CNN, filters = shot_embed_size\n",
    "    5. GRU\n",
    "    '''\n",
    "    # each input: 三個維度, rally shot feature\n",
    "    input_others = keras.Input(shape=(rally_size, shot_size, feature_dim[0]))\n",
    "    input_space = keras.Input(shape=(rally_size, shot_size))\n",
    "    input_action = keras.Input(shape=(rally_size, shot_size))\n",
    "\n",
    "    # space & action 先做 embedding, 再和 others concat\n",
    "    embed_space_layer = Embedding(input_dim=feature_dim[1], output_dim=space_embed_size, mask_zero=True, name='Space_Embedding')\n",
    "    embed_action_layer = Embedding(input_dim=feature_dim[2], output_dim=action_embed_size, mask_zero=True, name='Action_Embedding')\n",
    "    masking_layer = Masking(mask_value=0)   # for input_others (還沒有經過mask)\n",
    "    concat_layer = Concatenate(name='Input_Concat')\n",
    "\n",
    "    embed_shot_layer = CNN_with_mask(kernel_size=3, filters=shot_embed_size, strides=3, name='Shot_Embedding')\n",
    "\n",
    "    cnn_layer = CNN_with_mask(kernel_size=3, filters=shot_embed_size, strides=1, name='CNN_Layer')\n",
    "    gru_layer = GRU(units=16, return_sequences=True, name='GRU_Layer')\n",
    "    dense_layer = Dense(units=3, activation='softmax')\n",
    "    reshape_layer = Reshape((-1, 1, 3))\n",
    "\n",
    "    # forward\n",
    "    inputs = [input_others, input_space, input_action]\n",
    "\n",
    "    embed_space = embed_space_layer(input_space)\n",
    "    embed_action = embed_action_layer(input_action)\n",
    "    masked_others = masking_layer(tf.cast(input_others, tf.float32))\n",
    "    embed_input = concat_layer([masked_others, embed_space, embed_action])\n",
    "    embed_shot = tf.squeeze(embed_shot_layer(embed_input), axis=2)\n",
    "\n",
    "    cnn_output = cnn_layer(embed_shot)\n",
    "    gru_output = gru_layer(cnn_output)\n",
    "    output = dense_layer(gru_output)\n",
    "    model = keras.Model(inputs=inputs, outputs=output, name='Classification')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Classification\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 14, 3, 36)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast (TFOpLambda)            (None, 14, 3, 36)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 14, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 14, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, 14, 3, 36)    0           tf.cast[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Space_Embedding (Embedding)     (None, 14, 3, 8)     152         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Action_Embedding (Embedding)    (None, 14, 3, 8)     128         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Input_Concat (Concatenate)      (None, 14, 3, 52)    0           masking[0][0]                    \n",
      "                                                                 Space_Embedding[0][0]            \n",
      "                                                                 Action_Embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "cnn_with_mask (CNN_with_mask)   (None, 14, 1, 16)    2512        Input_Concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 14, 16)       0           cnn_with_mask[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cnn_with_mask_1 (CNN_with_mask) (None, 14, 16)       784         tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "GRU_Layer (GRU)                 (None, 14, 16)       1632        cnn_with_mask_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 14, 3)        51          GRU_Layer[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,259\n",
      "Trainable params: 5,259\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rally_set_tensor.shape)\n",
    "# print(rally_space_set_tensor.shape)\n",
    "# print(rally_action_set_tensor.shape)\n",
    "# print(rally_result_set_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.call([rally_set_tensor, rally_space_set_tensor, rally_action_set_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(others_tensor, space_tensor, action_tensor, label_tensor):\n",
    "    l = label_tensor.shape[0]\n",
    "    split_persentage = int(l*0.7)\n",
    "\n",
    "    train_space = space_tensor[:split_persentage]\n",
    "    train_action = action_tensor[:split_persentage]\n",
    "    train_others = others_tensor[:split_persentage]\n",
    "    train_label = label_tensor[:split_persentage]\n",
    "\n",
    "    test_space = space_tensor[split_persentage:]\n",
    "    test_action = action_tensor[split_persentage:]\n",
    "    test_others = others_tensor[split_persentage:]\n",
    "    test_label = label_tensor[split_persentage:]\n",
    "\n",
    "    train_x = [train_others, train_space, train_action]\n",
    "    train_y = train_label\n",
    "\n",
    "    test_x = [test_others, test_space, test_action]\n",
    "    test_y = test_label\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = split_data(rally_set_tensor, rally_space_set_tensor, rally_action_set_tensor, rally_result_set_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularizer = tf.keras.regularizers.l2(0.01)\n",
    "optimizer = 'adam'\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "metrics = ['accuracy']\n",
    "epochs = 30\n",
    "# callbacks = tf.keras.callbacks.EarlyStopping(min_delta=0.002, patience=15, restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "29/29 [==============================] - 1s 4ms/step - loss: 0.0445 - accuracy: 0.2043\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.2051\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.2038\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.2039\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.2048\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 0.2047\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.2046\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.2059\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.2057\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.2060\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.2069\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.2060\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.2067\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.2076\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.2073\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.2081\n",
      "Epoch 17/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.2075\n",
      "Epoch 18/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.2066\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.2081\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.2079\n",
      "Epoch 21/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.2086\n",
      "Epoch 22/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.2088\n",
      "Epoch 23/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.2085\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.2095\n",
      "Epoch 25/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.2086\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.2091\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.2086\n",
      "Epoch 28/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.2069\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0380 - accuracy: 0.2085\n",
      "Epoch 30/30\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.2089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2956fb3e748>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.0670 - accuracy: 0.1907\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172\n"
     ]
    }
   ],
   "source": [
    "test_y_reshape = test_y.reshape(test_y.shape[0]*test_y.shape[1], 3)\n",
    "y_pred_reshape = y_pred.reshape(y_pred.shape[0]*y_pred.shape[1], 3)\n",
    "\n",
    "idx = [i for i in range(len(test_y_reshape)) if(any(test_y_reshape[i] == np.array([1, 1, 1])))]\n",
    "print(len(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_y_pred_reshape = np.argmax(y_pred_reshape[idx], axis=1)\n",
    "argmax_test_y_reshape = np.argmax(test_y_reshape[idx], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from evaluate import calculate_BS, f1, show_eval_result\n",
    "\n",
    "acc_score = accuracy_score(argmax_test_y_reshape, argmax_y_pred_reshape)\n",
    "f1_score = f1(argmax_test_y_reshape, argmax_y_pred_reshape)\n",
    "auc_score = roc_auc_score(test_y_reshape[idx, :], y_pred_reshape[idx, :], multi_class='ovr')\n",
    "BS = calculate_BS(test_y_reshape[idx, :], y_pred_reshape[idx, :], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.88\n",
      "f1:         0.97\n",
      "auc:        0.97\n",
      "BS:         0.03, 0.07, 0.07\n",
      "mean of BS: 0.05\n"
     ]
    }
   ],
   "source": [
    "show_eval_result(acc_score, f1_score, auc_score, BS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from other_model import prosenet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prosenet_model(shot_sequence_shape=(10, 3, 16))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SportScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5a07162fe3afdd7b480234d7b349d638e7b8aabfdb46dc5c5983105b59f4026"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

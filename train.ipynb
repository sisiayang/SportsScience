{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from keras.layers import Embedding, Masking, Concatenate, GRU, Dense, Reshape\n",
    "from model import CNN_with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding_data(df):\n",
    "    '''\n",
    "    one df represents one game\n",
    "    split: space, action, player(?), error&score\n",
    "    label: 發球方是否得分？\n",
    "    '''\n",
    "    col = df.columns\n",
    "    space_col = [c for c in df.columns if 'Space' in c]\n",
    "    action_col = [c for c in df.columns if 'Action' in c]\n",
    "    result_col = ['Errors', 'Score', 'Nothing']\n",
    "    others_col = [c for c in df.columns if c not in space_col and c not in action_col and c not in result_col and c != 'Game' and c != 'Rally']\n",
    "\n",
    "    team_col = [c for c in df.columns if 'Team' in c]\n",
    "\n",
    "    rally_set = []\n",
    "    rally_space_set = []\n",
    "    rally_action_set = []\n",
    "    rally_result_set = []\n",
    "    for _, df_rally in df.groupby(['Game', 'Rally']):   # each rally in one game\n",
    "        # print(df_rally)\n",
    "        curr_team = df.iloc[df_rally.index[0]][team_col].tolist()\n",
    "        shot_set = []\n",
    "        shot_space_set = []\n",
    "        shot_action_set = []\n",
    "        shot_result_set = []\n",
    "        \n",
    "        atk_sequence = []\n",
    "        atk_space_sequence = []\n",
    "        atk_action_sequence = []\n",
    "        atk_result = []\n",
    "        \n",
    "        for _, shot in df_rally.iterrows():\n",
    "            if(shot[team_col].tolist() != curr_team):\n",
    "                shot_set.append(atk_sequence)\n",
    "                shot_space_set.append(atk_space_sequence)\n",
    "                shot_action_set.append(atk_action_sequence)\n",
    "                shot_result_set.append(atk_result)   # 最後一動的結果 -> predict object\n",
    "                \n",
    "                curr_team = shot[team_col].tolist()\n",
    "\n",
    "                atk_sequence = []\n",
    "                atk_space_sequence = []\n",
    "                atk_action_sequence = []\n",
    "\n",
    "            atk_space_sequence.append(shot[space_col])\n",
    "            atk_action_sequence.append(shot[action_col])\n",
    "            atk_sequence.append(shot[others_col])\n",
    "            atk_result = shot[result_col]\n",
    "        \n",
    "        # the last shot\n",
    "        shot_set.append(atk_sequence)\n",
    "        shot_space_set.append(atk_space_sequence)\n",
    "        shot_action_set.append(atk_action_sequence)\n",
    "        shot_result_set.append(atk_result)\n",
    "\n",
    "        # one rally has been finished\n",
    "        shot_set = pad_sequences(shot_set, maxlen=3, padding='post')\n",
    "        shot_space_set = pad_sequences(shot_space_set, maxlen=3, padding='post')\n",
    "        shot_action_set = pad_sequences(shot_action_set, maxlen=3, padding='post')\n",
    "\n",
    "        # one rally has been finished\n",
    "        rally_set.append(shot_set)\n",
    "        rally_space_set.append(shot_space_set)\n",
    "        rally_action_set.append(shot_action_set)\n",
    "        rally_result_set.append(shot_result_set)\n",
    "\n",
    "    padded_rally_set = pad_sequences(rally_set, dtype=float, padding='post')\n",
    "    padded_rally_space_set = pad_sequences(rally_space_set, dtype=float, padding='post')\n",
    "    padded_rally_action_set = pad_sequences(rally_action_set, dtype=float, padding='post')\n",
    "    padded_rally_result_set = pad_sequences(rally_result_set, dtype=float, padding='post')\n",
    "    \n",
    "    return padded_rally_set, padded_rally_space_set, padded_rally_action_set, padded_rally_result_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "\n",
    "space_replace = {list(df.groupby('Space').groups.keys())[i]: i+1 for i in range(len(df.groupby('Space')))}\n",
    "action_replace = {list(df.groupby('Action').groups.keys())[i]: i+1 for i in range(len(df.groupby('Action')))}\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Team', 'No.'])\n",
    "df = df.replace(space_replace)\n",
    "df = df.replace(action_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1292, 14, 3, 36)\n",
      "(1292, 14, 3, 1)\n",
      "(1292, 14, 3, 1)\n",
      "(1292, 14, 3)\n"
     ]
    }
   ],
   "source": [
    "rally_set, rally_space_set, rally_action_set, rally_result_set = get_padding_data(df)\n",
    "\n",
    "# rally數, 最大回合數in one rally, 3, feature數\n",
    "print(rally_set.shape)\n",
    "print(rally_space_set.shape)\n",
    "print(rally_action_set.shape)\n",
    "print(rally_result_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_space_set = rally_space_set.squeeze()\n",
    "rally_action_set = rally_action_set.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "rally_set_tensor = tf.convert_to_tensor(rally_set)\n",
    "rally_space_set_tensor = tf.convert_to_tensor(rally_space_set)\n",
    "rally_action_set_tensor = tf.convert_to_tensor(rally_action_set)\n",
    "rally_result_set_tensor = tf.convert_to_tensor(rally_result_set)\n",
    "\n",
    "rally_result_set_tensor = tf.where(tf.math.is_nan(rally_result_set_tensor), 0.0, rally_result_set_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rally_num = rally_set.shape[0]\n",
    "rally_size = rally_set.shape[1]\n",
    "shot_size = 3\n",
    "feature_dim = (rally_set.shape[-1], len(df.groupby('Space'))+1, len(df.groupby('Action'))+1)\n",
    "space_embed_size = 8\n",
    "action_embed_size = 8\n",
    "shot_embed_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size):\n",
    "    '''\n",
    "    framework: \n",
    "    1. 對 space, action 做 embeding, (input, output) = (feature_dim, embed_size)\n",
    "    2. concat space, action, others 成一個 embedded vector for each atk, (input) =  ([feature_dim, embed_size, embed_size])\n",
    "    3. 先做 embedding\n",
    "    4. CNN, filters = shot_embed_size\n",
    "    5. GRU\n",
    "    '''\n",
    "    # each input: 三個維度, rally shot feature\n",
    "    input_others = keras.Input(shape=(rally_size, shot_size, feature_dim[0]))\n",
    "    input_space = keras.Input(shape=(rally_size, shot_size))\n",
    "    input_action = keras.Input(shape=(rally_size, shot_size))\n",
    "\n",
    "    # space & action 先做 embedding, 再和 others concat\n",
    "    embed_space_layer = Embedding(input_dim=feature_dim[1], output_dim=space_embed_size, mask_zero=True, name='Space_Embedding')\n",
    "    embed_action_layer = Embedding(input_dim=feature_dim[2], output_dim=action_embed_size, mask_zero=True, name='Action_Embedding')\n",
    "    masking_layer = Masking(mask_value=0)   # for input_others (還沒有經過mask)\n",
    "    concat_layer = Concatenate(name='Input_Concat')\n",
    "\n",
    "    embed_shot_layer = CNN_with_mask(kernel_size=3, filters=shot_embed_size, strides=3, name='Shot_Embedding')\n",
    "\n",
    "    cnn_layer = CNN_with_mask(kernel_size=3, filters=shot_embed_size, strides=1, name='CNN_Layer')\n",
    "    gru_layer = GRU(units=16, return_sequences=True, name='GRU_Layer')\n",
    "    dense_layer = Dense(units=3, activation='softmax')\n",
    "    reshape_layer = Reshape((-1, 1, 3))\n",
    "\n",
    "    # forward\n",
    "    inputs = [input_others, input_space, input_action]\n",
    "\n",
    "    embed_space = embed_space_layer(input_space)\n",
    "    embed_action = embed_action_layer(input_action)\n",
    "    masked_others = masking_layer(tf.cast(input_others, tf.float32))\n",
    "    embed_input = concat_layer([masked_others, embed_space, embed_action])\n",
    "    embed_shot = tf.squeeze(embed_shot_layer(embed_input), axis=2)\n",
    "\n",
    "    cnn_output = cnn_layer(embed_shot)\n",
    "    gru_output = gru_layer(cnn_output)\n",
    "    output = dense_layer(gru_output)\n",
    "    model = keras.Model(inputs=inputs, outputs=output, name='Classification')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Classification\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 14, 3, 36)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_4 (TFOpLambda)          (None, 14, 3, 36)    0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 14, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           [(None, 14, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_4 (Masking)             (None, 14, 3, 36)    0           tf.cast_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Space_Embedding (Embedding)     (None, 14, 3, 8)     152         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Action_Embedding (Embedding)    (None, 14, 3, 8)     128         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Input_Concat (Concatenate)      (None, 14, 3, 52)    0           masking_4[0][0]                  \n",
      "                                                                 Space_Embedding[0][0]            \n",
      "                                                                 Action_Embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "cnn_with_mask_8 (CNN_with_mask) (None, 14, 1, 16)    2512        Input_Concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_4 (TFOpLam (None, 14, 16)       0           cnn_with_mask_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "cnn_with_mask_9 (CNN_with_mask) (None, 14, 16)       784         tf.compat.v1.squeeze_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "GRU_Layer (GRU)                 (None, 14, 16)       1632        cnn_with_mask_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 14, 3)        51          GRU_Layer[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,259\n",
      "Trainable params: 5,259\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(feature_dim, space_embed_size, action_embed_size, shot_embed_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rally_set_tensor.shape)\n",
    "# print(rally_space_set_tensor.shape)\n",
    "# print(rally_action_set_tensor.shape)\n",
    "# print(rally_result_set_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.call([rally_set_tensor, rally_space_set_tensor, rally_action_set_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(others_tensor, space_tensor, action_tensor, label_tensor):\n",
    "    l = label_tensor.shape[0]\n",
    "    split_persentage = int(l*0.7)\n",
    "\n",
    "    train_space = space_tensor[:split_persentage]\n",
    "    train_action = action_tensor[:split_persentage]\n",
    "    train_others = others_tensor[:split_persentage]\n",
    "    train_label = label_tensor[:split_persentage]\n",
    "\n",
    "    test_space = space_tensor[split_persentage:]\n",
    "    test_action = action_tensor[split_persentage:]\n",
    "    test_others = others_tensor[split_persentage:]\n",
    "    test_label = label_tensor[split_persentage:]\n",
    "\n",
    "    train_x = [train_others, train_space, train_action]\n",
    "    train_y = train_label\n",
    "\n",
    "    test_x = [test_others, test_space, test_action]\n",
    "    test_y = test_label\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = split_data(rally_set_tensor, rally_space_set_tensor, rally_action_set_tensor, rally_result_set_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):    \n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        \n",
    "        recall = TP / (Positives+K.epsilon())    \n",
    "        return recall \n",
    "    \n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision \n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularizer = tf.keras.regularizers.l2(0.01)\n",
    "optimizer = 'adam'\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "metrics = [f1, 'accuracy']\n",
    "epochs = 50\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(min_delta=0.002, patience=15, restore_best_weights=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29/29 [==============================] - 1s 4ms/step - loss: 0.2377 - f1: 0.0000e+00 - accuracy: 0.1065\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2403 - f1: 0.0000e+00 - accuracy: 0.0816\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2296 - f1: 0.1140 - accuracy: 0.0944\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2220 - f1: 0.3589 - accuracy: 0.0937\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2191 - f1: 0.3578 - accuracy: 0.0937\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2164 - f1: 0.3616 - accuracy: 0.0937\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2130 - f1: 0.3567 - accuracy: 0.0937\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2085 - f1: 0.3652 - accuracy: 0.0937\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2020 - f1: 0.3794 - accuracy: 0.0938\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1946 - f1: 0.4279 - accuracy: 0.1027\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1867 - f1: 0.4600 - accuracy: 0.1219\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1793 - f1: 0.5113 - accuracy: 0.1290\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1733 - f1: 0.5607 - accuracy: 0.1335\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1680 - f1: 0.5809 - accuracy: 0.1379\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1637 - f1: 0.5879 - accuracy: 0.1410\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1597 - f1: 0.5953 - accuracy: 0.1445\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1415 - f1: 0.6882 - accuracy: 0.1669\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1263 - f1: 0.7783 - accuracy: 0.1865\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1213 - f1: 0.7944 - accuracy: 0.1886\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1181 - f1: 0.8030 - accuracy: 0.1909\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1161 - f1: 0.8063 - accuracy: 0.1923\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1144 - f1: 0.8103 - accuracy: 0.1903\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1133 - f1: 0.8143 - accuracy: 0.1922\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1123 - f1: 0.8110 - accuracy: 0.1936\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1115 - f1: 0.8136 - accuracy: 0.1941\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1106 - f1: 0.8142 - accuracy: 0.1942\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1102 - f1: 0.8157 - accuracy: 0.1945\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1094 - f1: 0.8177 - accuracy: 0.1947\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1090 - f1: 0.8163 - accuracy: 0.1956\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1084 - f1: 0.8175 - accuracy: 0.1955\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1081 - f1: 0.8142 - accuracy: 0.1954\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1078 - f1: 0.8195 - accuracy: 0.1967\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1074 - f1: 0.8166 - accuracy: 0.1959\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1072 - f1: 0.8186 - accuracy: 0.1959\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1066 - f1: 0.8183 - accuracy: 0.1961\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1062 - f1: 0.8201 - accuracy: 0.1967\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1061 - f1: 0.8193 - accuracy: 0.1956\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1059 - f1: 0.8195 - accuracy: 0.1967\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1054 - f1: 0.8187 - accuracy: 0.1966\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1054 - f1: 0.8238 - accuracy: 0.1970\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1054 - f1: 0.8261 - accuracy: 0.1970\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1047 - f1: 0.8234 - accuracy: 0.1974\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1048 - f1: 0.8201 - accuracy: 0.1957\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1043 - f1: 0.8255 - accuracy: 0.1983\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1041 - f1: 0.8248 - accuracy: 0.1971\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1038 - f1: 0.8268 - accuracy: 0.1975\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1037 - f1: 0.8265 - accuracy: 0.1979\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1034 - f1: 0.8249 - accuracy: 0.1979\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1039 - f1: 0.8251 - accuracy: 0.1970\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1034 - f1: 0.8299 - accuracy: 0.1978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2098ec9eba8>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1095 - f1: 0.8251 - accuracy: 0.1924\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_reshape = test_y.reshape(test_y.shape[0]*test_y.shape[1], 3)\n",
    "y_pred_reshape = y_pred.reshape(y_pred.shape[0]*y_pred.shape[1], 3)\n",
    "\n",
    "idx = [i for i in range(len(test_y_reshape)) if(any(test_y_reshape[i] == np.array([1, 1, 1])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argmax(y_pred_reshape[idx], axis=1)\n",
    "reshape_y = np.argmax(test_y_reshape[idx], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1172"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reshape_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8916382252559727"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, brier_score_loss, roc_auc_score\n",
    "\n",
    "accuracy_score(reshape_y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.9821655549704273>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(reshape_y, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_reshape = test_y.reshape(test_y.shape[0]*test_y.shape[1], 3)\n",
    "y_pred_reshape = y_pred.reshape(y_pred.shape[0]*y_pred.shape[1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [i for i in range(len(test_y_reshape)) if(any(test_y_reshape[i] == np.array([1, 1, 1])))] # 實際需要被evaluate的資料的index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2775158 , 0.51450956, 0.20797464],\n",
       "       [0.6010162 , 0.30368918, 0.09529448],\n",
       "       [0.05402251, 0.07066091, 0.8753166 ],\n",
       "       ...,\n",
       "       [0.11287484, 0.44157866, 0.4455465 ],\n",
       "       [0.6006503 , 0.29929912, 0.10005054],\n",
       "       [0.80790824, 0.15942068, 0.03267108]], dtype=float32)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_reshape[idx, :]  # 所有需要被evaluate的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9497697902455805"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_y_reshape[idx, :], y_pred_reshape[idx, :], multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07197804087238842"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_loss(test_y_reshape[idx, 0], y_pred_reshape[idx, 0])    # errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.120689415114626"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_loss(test_y_reshape[idx, 1], y_pred_reshape[idx, 1])    # nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.078496437501725"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_loss(test_y_reshape[idx, 2], y_pred_reshape[idx, 2])    # score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import calculate_BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BS': [0.07197804087238842, 0.120689415114626, 0.078496437501725],\n",
       " 'mean_BS': 0.09038796449624646}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_BS(test_y_reshape[idx, :], y_pred_reshape[idx, :], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SportScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5a07162fe3afdd7b480234d7b349d638e7b8aabfdb46dc5c5983105b59f4026"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
